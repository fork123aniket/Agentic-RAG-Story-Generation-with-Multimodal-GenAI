# ğŸ“– **Agentic RAG Storytelling with Multimodal AI**  

### **Transform Images into Engaging Narratives with Generative AI**  

## ğŸš€ Overview  
This project implements an **Agentic RAG (Retrieval-Augmented Generation) workflow** using **LangChain, LangGraph, and multimodal AI** to generate meaningful and engaging stories from user-uploaded images. The system seamlessly integrates **retrieval-based reasoning** with **generative AI capabilities**, leveraging **LLMs, vector search, and vision models** to produce immersive narratives.  

---

## ğŸ¯ **Why Agentic RAG?**  
This project demonstrates how **LLMs, retrieval systems, and vision models** can collaborate to generate dynamic and **engaging AI-generated stories**. The **agentic workflow** makes it possible to balance **creativity and factuality**, ensuring a seamless storytelling experience.

---

## âœ¨ Key Features  
ğŸ”¹ **Multimodal Input Handling**: Accepts **image uploads** and processes them for storytelling.  
ğŸ”¹ **Retrieval-Augmented Generation (RAG)**: Enhances story coherence using **retrieved knowledge**.  
ğŸ”¹ **Agentic AI Workflow**: Dynamically selects **retriever** or **generator** based on available data.  
ğŸ”¹ **LLM-Driven Storytelling**: Generates **rich, context-aware** narratives using **GPT-4o**.  
ğŸ”¹ **Chroma Vector Search**: Stores and retrieves **image-text embeddings** for enhanced relevance.  
ğŸ”¹ **Cloud Integration**: Supports **Cloudinary** for image hosting and efficient handling.  
ğŸ”¹ **Streamlit UI**: Interactive interface for seamless user interaction.  

---

## ğŸ›  **Technology Stack**  

This project leverages cutting-edge **LLMs, multimodal AI, and retrieval-based techniques** to ensure seamless and engaging storytelling.  

| **Category**       | **Technology Used** |
|--------------------|--------------------|
| ğŸ¤– **LLM**         | InternVL2 - 40B |
| ğŸ–¼ **Vision Model** | CLIP (Contrastive Language-Image Pretraining) |
| ğŸ” **Retriever**    | ChromaDB Vector Search |
| ğŸ“œ **RAG Framework** | LangChain, LangGraph |
| ğŸŒ **Web Interface** | Streamlit |
| â˜ï¸ **Cloud Storage** | Cloudinary API |
| ğŸ¤ **Text-to-Speech** | pyttsx3 |

These technologies work together to **process images, retrieve relevant context, and generate rich, meaningful narratives**.  

---

## ğŸ¯ **Agentic RAG Gen AI Workflow**  

This project follows an **Agentic RAG (Retrieval-Augmented Generation) framework**, meaning the system **autonomously** decides when to retrieve external knowledge and when to generate stories based on the input.  

### **How It Works**  
1ï¸âƒ£ **Image Upload**: Users provide an image via the **Streamlit UI**.  
2ï¸âƒ£ **Embedding Generation**: The image is processed using **Hugging Face CLIP** embeddings.  
3ï¸âƒ£ **Retrieval Decision**:  
   - If relevant **stories exist**, the retriever fetches them for context.  
   - If no prior data is found, the system **generates a story from scratch**.  
4ï¸âƒ£ **LLM-Based Generation**: Uses **GPT-4o** to craft a compelling story.  
5ï¸âƒ£ **User Display**: The generated story is displayed in the UI.  
6ï¸âƒ£ **Audio Narration** â€“ Converts generated stories into speech.  

This approach ensures **optimal use of existing knowledge** while allowing for **creative storytelling** when necessary.  

---

## ğŸ›  **Workflow Architecture**  

The diagram below illustrates the **modular AI workflow** used in this project.  

![Visual Storytelling Workflow](image.png)  

### **Workflow Breakdown**  
- **Start** â†’ Initializes the workflow.  
- **LLM Node** â†’ Processes input data and decides next steps.  
- **Tools Node** â†’ Determines whether to retrieve past stories or generate new ones.  
- **Retriever Node** â†’ If prior knowledge exists, retrieves related image-text pairs.  
- **Generator Node** â†’ Uses the **LLM** to create an engaging story.  
- **End** â†’ Displays the final generated narrative to the user.  

This **state-driven agentic AI approach** ensures that each decision maximizes the **relevance and creativity** of the generated content.  

---

## ğŸ“Œ **Installation & Usage**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/fork123aniket/VLM-powered-Multimodal-Conversational-AI-Bot.git
cd VLM-powered-Multimodal-Conversational-AI-Bot
```

### **2ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up Cloudinary for Image Hosting**  
Replace the placeholders in `Agentic_Workflow.py`:  
```python
cloudinary.config(
    cloud_name='your_cloud_name',
    api_key='your_api_key',
    api_secret='your_secret_key'
)
```

### **4ï¸âƒ£ Run the Streamlit App**  
```bash
streamlit run Agentic_Workflow.py
```

### **5ï¸âƒ£ Upload an Image & Enjoy AI-Powered Storytelling!**  

---

## ğŸ“‚ **Project Structure**  

The project is structured as follows:  

```
ğŸ“¦ Agentic_RAG_Storytelling
â”œâ”€â”€ ğŸ“œ Agentic_Workflow.py      # Core agentic workflow implementation
â”œâ”€â”€ ğŸ“œ requirements.txt         # Dependencies list
â”œâ”€â”€ ğŸ“œ README.md                # Project documentation